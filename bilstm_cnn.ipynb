{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"bilstm_cnn.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPrnX2B7/jbra33CIWUtrBp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hgQ75WlWqUCf","executionInfo":{"status":"ok","timestamp":1638689601115,"user_tz":-420,"elapsed":280,"user":{"displayName":"colab google","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15243667049266710387"}},"outputId":"3dc28cdd-7751-4b90-ff63-13d48720b0fc"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lhsb1kGMxWHK","executionInfo":{"status":"ok","timestamp":1638689602433,"user_tz":-420,"elapsed":342,"user":{"displayName":"colab google","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15243667049266710387"}},"outputId":"0686ee8d-7439-4231-c3b8-780e77983d0d"},"source":["cd /content/drive/MyDrive/ner"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/ner\n"]}]},{"cell_type":"code","metadata":{"id":"iPKCPJmV5qM7","executionInfo":{"status":"ok","timestamp":1638689604106,"user_tz":-420,"elapsed":1268,"user":{"displayName":"colab google","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15243667049266710387"}}},"source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import spacy\n","import time\n","import random\n","import pandas as pd\n","import torch.nn.functional as F\n","from torchtext.legacy import data, datasets"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"1tllm0MLxGEG","executionInfo":{"status":"ok","timestamp":1638689604108,"user_tz":-420,"elapsed":5,"user":{"displayName":"colab google","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15243667049266710387"}}},"source":["def readfile(filename, *, encoding=\"UTF8\"):\n","    '''\n","    read file\n","    return format :\n","    [ ['EU', 'B-ORG'], ['rejects', 'O'], ['German', 'B-MISC'], ['call', 'O'], ['to', 'O'], ['boycott', 'O'], ['British', 'B-MISC'], ['lamb', 'O'], ['.', 'O'] ]\n","    '''\n","    with open(filename, mode='r', encoding=encoding) as f:\n","        sentences = []\n","        sentence = []\n","        for line in f:\n","            if len(line) == 0 or line.startswith('-DOCSTART') or line[0] == \"\\n\":   \n","                if len(sentence) > 0:\n","                    sentences.append(sentence)\n","                    sentence = []\n","                continue\n","            splits = line.split(' ')\n","            sentence.append([splits[0], splits[-1]])\n","\n","    if len(sentence) > 0:\n","        sentences.append(sentence)\n","        sentence = []\n","    return sentences"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"zXX1LgfRzZ1h","executionInfo":{"status":"ok","timestamp":1638689605052,"user_tz":-420,"elapsed":948,"user":{"displayName":"colab google","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15243667049266710387"}}},"source":["train_data = readfile('conll2003/train.txt')\n","valid_data = readfile('conll2003/valid.txt')\n","test_data = readfile('conll2003/test.txt')"],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y_SPsOyBzsQN","executionInfo":{"status":"ok","timestamp":1638689605054,"user_tz":-420,"elapsed":19,"user":{"displayName":"colab google","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15243667049266710387"}},"outputId":"83d59926-4e4f-4ff7-ba95-697327499ef1"},"source":["print(len(train_data))\n","print(len(valid_data))\n","print(len(test_data))"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["14041\n","3250\n","3453\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jb0hGWp_zx1L","executionInfo":{"status":"ok","timestamp":1638689605054,"user_tz":-420,"elapsed":9,"user":{"displayName":"colab google","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15243667049266710387"}},"outputId":"04901ff7-fda9-4269-cc39-4fcffe651474"},"source":["train_data[0]"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['EU', 'B-ORG\\n'],\n"," ['rejects', 'O\\n'],\n"," ['German', 'B-MISC\\n'],\n"," ['call', 'O\\n'],\n"," ['to', 'O\\n'],\n"," ['boycott', 'O\\n'],\n"," ['British', 'B-MISC\\n'],\n"," ['lamb', 'O\\n'],\n"," ['.', 'O\\n']]"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"qCC2gQBrz0LT","executionInfo":{"status":"ok","timestamp":1638689605055,"user_tz":-420,"elapsed":6,"user":{"displayName":"colab google","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15243667049266710387"}}},"source":["def clean_data(dataset):\n","    for sent in dataset:\n","        for word in sent:\n","            word[-1] = word[-1].strip('\\n')\n","    return dataset"],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"id":"lq8Ie-RL3X9s","executionInfo":{"status":"ok","timestamp":1638689605648,"user_tz":-420,"elapsed":4,"user":{"displayName":"colab google","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15243667049266710387"}}},"source":["train_data = clean_data(train_data)\n","valid_data = clean_data(valid_data)\n","test_data = clean_data(test_data)"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kjSm1-1Kdq15","executionInfo":{"status":"ok","timestamp":1638689606103,"user_tz":-420,"elapsed":8,"user":{"displayName":"colab google","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15243667049266710387"}},"outputId":"3806fa48-aaaf-4c39-d8f3-991ba9757b3f"},"source":["train_data[0]"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[['EU', 'B-ORG'],\n"," ['rejects', 'O'],\n"," ['German', 'B-MISC'],\n"," ['call', 'O'],\n"," ['to', 'O'],\n"," ['boycott', 'O'],\n"," ['British', 'B-MISC'],\n"," ['lamb', 'O'],\n"," ['.', 'O']]"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"dE7Tyb8WgpYo","executionInfo":{"status":"ok","timestamp":1638689606104,"user_tz":-420,"elapsed":5,"user":{"displayName":"colab google","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15243667049266710387"}}},"source":["SEED = 0\n","\n","random.seed(SEED)\n","torch.manual_seed(SEED)\n","torch.backends.cudnn.deterministic = True"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"id":"3AcSDIBYsUMg","executionInfo":{"status":"ok","timestamp":1638689606105,"user_tz":-420,"elapsed":5,"user":{"displayName":"colab google","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15243667049266710387"}}},"source":["def split_data(dataset):\n","    text = []\n","    label = []\n","    for sent in dataset:\n","        tokens = []\n","        tags = []\n","        for word in sent:\n","            tokens.append(word[0])\n","            tags.append(word[-1])\n","        text.append(' '.join(tokens))\n","        label.append(' '.join(tags))\n","    return text, label"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"jPjbBC350RhI","executionInfo":{"status":"ok","timestamp":1638689606565,"user_tz":-420,"elapsed":2,"user":{"displayName":"colab google","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15243667049266710387"}}},"source":["train_text, train_label = split_data(train_data)\n","valid_text, valid_label = split_data(valid_data)\n","test_text, test_label = split_data(test_data)"],"execution_count":13,"outputs":[]},{"cell_type":"code","metadata":{"id":"aZwpacK215Zc","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1638689606998,"user_tz":-420,"elapsed":24,"user":{"displayName":"colab google","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15243667049266710387"}},"outputId":"cfffa06f-6bd0-4e93-a610-dd6cc23d3b09"},"source":["train_df = pd.DataFrame({'text' : train_text, 'label' : train_label})\n","valid_df = pd.DataFrame({'text' : valid_text, 'label' : valid_label})\n","test_df = pd.DataFrame({'text' : test_text, 'label' : test_label})\n","\n","train_df.head(5)"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>EU rejects German call to boycott British lamb .</td>\n","      <td>B-ORG O B-MISC O O O B-MISC O O</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Peter Blackburn</td>\n","      <td>B-PER I-PER</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>BRUSSELS 1996-08-22</td>\n","      <td>B-LOC O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>The European Commission said on Thursday it di...</td>\n","      <td>O B-ORG I-ORG O O O O O O B-MISC O O O O O B-M...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Germany 's representative to the European Unio...</td>\n","      <td>B-LOC O O O O B-ORG I-ORG O O O B-PER I-PER O ...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text                                              label\n","0   EU rejects German call to boycott British lamb .                    B-ORG O B-MISC O O O B-MISC O O\n","1                                    Peter Blackburn                                        B-PER I-PER\n","2                                BRUSSELS 1996-08-22                                            B-LOC O\n","3  The European Commission said on Thursday it di...  O B-ORG I-ORG O O O O O O B-MISC O O O O O B-M...\n","4  Germany 's representative to the European Unio...  B-LOC O O O O B-ORG I-ORG O O O B-PER I-PER O ..."]},"metadata":{},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"2MDdJ1Qag1kD","executionInfo":{"status":"ok","timestamp":1638689607858,"user_tz":-420,"elapsed":4,"user":{"displayName":"colab google","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15243667049266710387"}}},"source":["train_df.to_csv('data/train.csv')\n","valid_df.to_csv('data/valid.csv')\n","test_df.to_csv('data/test.csv')"],"execution_count":15,"outputs":[]},{"cell_type":"code","metadata":{"id":"5slYSE2C2GAC","executionInfo":{"status":"ok","timestamp":1638689608265,"user_tz":-420,"elapsed":5,"user":{"displayName":"colab google","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15243667049266710387"}}},"source":["TEXT = data.Field()\n","NESTING_CHAR = data.Field(tokenize=list)\n","CHAR = data.NestedField(NESTING_CHAR)\n","LABEL = data.Field(unk_token = None)\n","fields = ((None, None), (('text', 'char'), (TEXT, CHAR)), ('label', LABEL))"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"8raWQpRH43ej","executionInfo":{"status":"ok","timestamp":1638689610677,"user_tz":-420,"elapsed":1183,"user":{"displayName":"colab google","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15243667049266710387"}}},"source":["train_data, valid_data, test_data = data.TabularDataset.splits(\n","                                        path = 'data',\n","                                        train = 'train.csv',\n","                                        validation = 'valid.csv',\n","                                        test = 'test.csv',\n","                                        format = 'csv',\n","                                        fields = fields,\n","                                        skip_header = True\n",")"],"execution_count":17,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eo_ucqxR5nmq","executionInfo":{"status":"ok","timestamp":1638689611788,"user_tz":-420,"elapsed":12,"user":{"displayName":"colab google","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15243667049266710387"}},"outputId":"5e68de62-a2ce-415f-aa76-161f1a2ed2e9"},"source":["vars(train_data[0])"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'char': [['E', 'U'],\n","  ['r', 'e', 'j', 'e', 'c', 't', 's'],\n","  ['G', 'e', 'r', 'm', 'a', 'n'],\n","  ['c', 'a', 'l', 'l'],\n","  ['t', 'o'],\n","  ['b', 'o', 'y', 'c', 'o', 't', 't'],\n","  ['B', 'r', 'i', 't', 'i', 's', 'h'],\n","  ['l', 'a', 'm', 'b'],\n","  ['.']],\n"," 'label': ['B-ORG', 'O', 'B-MISC', 'O', 'O', 'O', 'B-MISC', 'O', 'O'],\n"," 'text': ['EU',\n","  'rejects',\n","  'German',\n","  'call',\n","  'to',\n","  'boycott',\n","  'British',\n","  'lamb',\n","  '.']}"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","metadata":{"id":"vMz1x_Jy5vAm","executionInfo":{"status":"ok","timestamp":1638689613959,"user_tz":-420,"elapsed":1750,"user":{"displayName":"colab google","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15243667049266710387"}}},"source":["MIN_FREQ = 2\n","TEXT.build_vocab(train_data,\n","                 min_freq = MIN_FREQ,\n","                 vectors = 'glove.6B.50d',\n","                 unk_init = torch.Tensor.normal_)\n","CHAR.build_vocab(train_data)\n","LABEL.build_vocab(train_data)"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"14ZDd6gIh9uo","executionInfo":{"status":"ok","timestamp":1638689613962,"user_tz":-420,"elapsed":24,"user":{"displayName":"colab google","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15243667049266710387"}},"outputId":"dc0d87d7-ff3a-42aa-f4ac-1ea74a4cc5f6"},"source":["vars(LABEL.vocab)"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'freqs': Counter({'B-LOC': 7140,\n","          'B-MISC': 3438,\n","          'B-ORG': 6321,\n","          'B-PER': 6600,\n","          'I-LOC': 1157,\n","          'I-MISC': 1155,\n","          'I-ORG': 3704,\n","          'I-PER': 4528,\n","          'O': 169578}),\n"," 'itos': ['<pad>',\n","  'O',\n","  'B-LOC',\n","  'B-PER',\n","  'B-ORG',\n","  'I-PER',\n","  'I-ORG',\n","  'B-MISC',\n","  'I-LOC',\n","  'I-MISC'],\n"," 'stoi': defaultdict(None,\n","             {'<pad>': 0,\n","              'B-LOC': 2,\n","              'B-MISC': 7,\n","              'B-ORG': 4,\n","              'B-PER': 3,\n","              'I-LOC': 8,\n","              'I-MISC': 9,\n","              'I-ORG': 6,\n","              'I-PER': 5,\n","              'O': 1}),\n"," 'unk_index': None,\n"," 'vectors': None}"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"6Bov4cwjiF-9","executionInfo":{"status":"ok","timestamp":1638689618092,"user_tz":-420,"elapsed":280,"user":{"displayName":"colab google","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15243667049266710387"}}},"source":["BATCH_SIZE = 128\n","\n","device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","train_iter, valid_iter, test_iter = data.BucketIterator.splits(\n","                                        (train_data, valid_data, test_data),\n","                                        sort = False,\n","                                        batch_size = BATCH_SIZE,\n","                                        device = device\n",")"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tferx7HgkWFE","executionInfo":{"status":"ok","timestamp":1638689620885,"user_tz":-420,"elapsed":282,"user":{"displayName":"colab google","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15243667049266710387"}}},"source":["class BiLSTM_CNN(nn.Module):\n","    def __init__(self, \n","                 word_vocab_size,\n","                 word_embedding_dim,\n","                 word_pad_idx,\n","                 char_vocab_size,\n","                 char_embedding_dim,\n","                 char_pad_idx, \n","                 hidden_dim, \n","                 output_dim, \n","                 n_layers,\n","                 n_filter,\n","                 cnn_kernel_size, \n","                 bidirectional, \n","                 lstm_dropout,\n","                 cnn_dropout,\n","                 fc_dropout,\n","                 emb_dropout):\n","        super().__init__()\n","        self.word_embedding = nn.Embedding(word_vocab_size, word_embedding_dim, padding_idx = word_pad_idx)   \n","        self.char_embedding = nn.Embedding(char_vocab_size, char_embedding_dim, padding_idx = char_pad_idx)\n","        self.cnn = nn.Conv1d(in_channels = char_embedding_dim, \n","                             out_channels = char_embedding_dim * n_filter, \n","                             kernel_size = cnn_kernel_size, \n","                             groups=char_embedding_dim) \n","        self.lstm = nn.LSTM(word_embedding_dim + char_embedding_dim * n_filter,\n","                            hidden_dim,\n","                            num_layers = n_layers,\n","                            bidirectional = bidirectional,\n","                            dropout = lstm_dropout if n_layers > 1 else 0)\n","        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, output_dim)\n","        self.fc_dropout = nn.Dropout(fc_dropout)\n","        self.cnn_dropout = nn.Dropout(cnn_dropout)\n","        self.emb_dropout = nn.Dropout(emb_dropout)\n","          \n","    def count_params(self):\n","        return sum(p.numel() for p in self.parameters() if p.requires_grad)\n","\n","    def forward(self, text, chars):\n","        #text = [sent, batch_size]\n","        #chars = [batch_size, sent, word]\n","        word_embedded = self.emb_dropout(self.word_embedding(text))\n","        #word_embedded = [sent, batch_size, word_embedding_dim]\n","\n","        char_embedded = self.emb_dropout(self.char_embedding(chars))\n","        #char_embedded = [batch_size, sent, word, char_embedding]\n","        (batch_size, sent, word, char_emb_dim) = char_embedded.shape\n","        char_cnn_max_out = torch.zeros(batch_size, sent, self.cnn.out_channels).to(device)\n","        for sent_i in range(sent):\n","            # sent_char_emb = [batch size, word length, char emb dim]\n","            sent_char_emb = char_embedded[:, sent_i, :, :]  # get the character field of sent i\n","            # sent_char_emb_p = [batch size, char emb dim, word length]\n","            sent_char_emb_p = sent_char_emb.permute(0, 2, 1)  # the channel (char emb dim) has to be the last dimension\n","            # char_cnn_sent_out = [batch size, out channels * char emb dim, word length - kernel size + 1]\n","            char_cnn_sent_out = torch.tanh(self.cnn(sent_char_emb_p))\n","            # max pooling over the word length dimension\n","            char_cnn_max_out[:, sent_i, :] = F.max_pool1d(char_cnn_sent_out, char_cnn_sent_out.shape[2]).squeeze(2)\n","        char_cnn = self.cnn_dropout(char_cnn_max_out)\n","        # concat word and char embedding\n","        # char_cnn_p = [sentence length, batch size, char emb dim * num filter]\n","        char_cnn_p = char_cnn_max_out.permute(1, 0, 2)\n","        embedded = torch.cat((word_embedded, char_cnn_p), dim = 2)\n","        outputs, (hidden, cell) = self.lstm(embedded)\n","        #output = [sent len, batch size, hid dim * n directions]\n","        #hidden/cell = [n layers * n directions, batch size, hid dim]\n","        pred = self.fc(self.fc_dropout(outputs))\n","        #pred = [sent, batch size, output dim]\n","        return pred"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"6gRNS1gjm4zN","executionInfo":{"status":"ok","timestamp":1638689624287,"user_tz":-420,"elapsed":267,"user":{"displayName":"colab google","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15243667049266710387"}}},"source":["model = BiLSTM_CNN(\n","            word_vocab_size = len(TEXT.vocab),\n","            word_embedding_dim = 50,\n","            word_pad_idx = TEXT.vocab.stoi['<pad>'],\n","            char_vocab_size = len(CHAR.vocab),\n","            char_embedding_dim = 25,\n","            char_pad_idx = CHAR.vocab.stoi['<pad'], \n","            hidden_dim = 200, \n","            output_dim = len(LABEL.vocab), \n","            n_layers = 2,\n","            n_filter = 5,\n","            cnn_kernel_size = 3, \n","            bidirectional = True, \n","            lstm_dropout = 0.25,\n","            cnn_dropout = 0.5,\n","            fc_dropout = 0.5,\n","            emb_dropout = 0.5\n",")"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZDANtR4WoyqY","executionInfo":{"status":"ok","timestamp":1638689626528,"user_tz":-420,"elapsed":269,"user":{"displayName":"colab google","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15243667049266710387"}},"outputId":"80801ee7-0717-49d1-8ed2-a043f3f4816b"},"source":["def init_weights(m):\n","    for name, param in m.named_parameters():\n","        nn.init.normal_(param.data, mean = 0, std = 0.1)\n","            \n","model.apply(init_weights)"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["BiLSTM_CNN(\n","  (word_embedding): Embedding(11984, 50, padding_idx=1)\n","  (char_embedding): Embedding(86, 25, padding_idx=0)\n","  (cnn): Conv1d(25, 125, kernel_size=(3,), stride=(1,), groups=25)\n","  (lstm): LSTM(175, 200, num_layers=2, dropout=0.25, bidirectional=True)\n","  (fc): Linear(in_features=400, out_features=10, bias=True)\n","  (fc_dropout): Dropout(p=0.5, inplace=False)\n","  (cnn_dropout): Dropout(p=0.5, inplace=False)\n","  (emb_dropout): Dropout(p=0.5, inplace=False)\n",")"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Mf_PWtSgpEF6","executionInfo":{"status":"ok","timestamp":1638689627447,"user_tz":-420,"elapsed":9,"user":{"displayName":"colab google","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15243667049266710387"}},"outputId":"eeabefb5-1a68-4d34-b2ff-5dd42ef93236"},"source":["print(f'The model has {model.count_params():,} trainable parameters')"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["The model has 2,172,260 trainable parameters\n"]}]},{"cell_type":"code","metadata":{"id":"DXIpTH6epYEa","executionInfo":{"status":"ok","timestamp":1638689628723,"user_tz":-420,"elapsed":8,"user":{"displayName":"colab google","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15243667049266710387"}}},"source":["pretrained_embeddings = TEXT.vocab.vectors\n","model.word_embedding.weight.data.copy_(pretrained_embeddings)\n","model.word_embedding.weight.data[TEXT.vocab.stoi['<pad>']] = torch.zeros(50)\n","model.char_embedding.weight.data[CHAR.vocab.stoi['<pad>']] = torch.zeros(25)"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fnvCN5-5p7BP","executionInfo":{"status":"ok","timestamp":1638689682315,"user_tz":-420,"elapsed":38683,"user":{"displayName":"colab google","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15243667049266710387"}},"outputId":"ec0c7f6c-9951-4a55-c92a-24f3ca608a2b"},"source":["optimizer = optim.Adam(model.parameters(), lr =  0.0105)\n","criterion = nn.CrossEntropyLoss(ignore_index = LABEL.vocab.stoi['<pad>'])\n","model.to(device)\n","criterion.to(device)"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["CrossEntropyLoss()"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"po4lmXX9qiKb","executionInfo":{"status":"ok","timestamp":1638689689278,"user_tz":-420,"elapsed":284,"user":{"displayName":"colab google","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15243667049266710387"}}},"source":["def categorical_accuracy(preds, y, tag_pad_idx):\n","    \"\"\"\n","    Returns accuracy per batch, i.e. if you get 8/10 right, this returns 0.8, NOT 8\n","    \"\"\"\n","    max_preds = preds.argmax(dim = 1, keepdim = True) # get the index of the max probability\n","    non_pad_elements = (y != tag_pad_idx).nonzero()\n","    correct = max_preds[non_pad_elements].squeeze(1).eq(y[non_pad_elements])\n","    return correct.sum() / y[non_pad_elements].shape[0]"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"Rf9VN0dorWTa","executionInfo":{"status":"ok","timestamp":1638689692571,"user_tz":-420,"elapsed":401,"user":{"displayName":"colab google","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15243667049266710387"}}},"source":["def train(model, iter, optimizer, criterion, tag_pad_idx):\n","    epoch_loss = 0\n","    epoch_acc = 0\n","    model.train()\n","\n","    for batch in iter:\n","        text = batch.text\n","        chars = batch.char\n","        label = batch.label\n","         #text = [sent len, batch size]\n","         #char = [batch, sent, word]\n","        optimizer.zero_grad()\n","        pred = model(text, chars)\n","        #pred = [sent len, batch size, output dim]\n","        #label = [sent len, batch size]\n","        pred = pred.view(-1, pred.shape[-1])\n","        #pred = [sent len * batch_size, output dim]\n","        label = label.view(-1)\n","        #label = [sent len * batch_size]\n","        loss = criterion(pred, label)\n","        acc = categorical_accuracy(pred, label, tag_pad_idx)\n","\n","        loss.backward()\n","        optimizer.step()\n","\n","        epoch_loss += loss.item()\n","        epoch_acc += acc.item()\n","    \n","    return epoch_loss / len(iter), epoch_acc / len(iter)"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"jiydQX-Jvvj8","executionInfo":{"status":"ok","timestamp":1638689693678,"user_tz":-420,"elapsed":12,"user":{"displayName":"colab google","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15243667049266710387"}}},"source":["def evaluate(model, iter, criterion, tag_pad_idx): \n","    epoch_loss = 0\n","    epoch_acc = 0  \n","    model.eval()\n","    \n","    with torch.no_grad():\n","        for batch in iter:\n","            text = batch.text\n","            label = batch.label\n","            chars = batch.char\n","            \n","            pred = model(text, chars)\n","            \n","            pred = pred.view(-1, pred.shape[-1])\n","            label = label.view(-1)\n","            \n","            loss = criterion(pred, label)\n","            \n","            acc = categorical_accuracy(pred, label, tag_pad_idx)\n","\n","            epoch_loss += loss.item()\n","            epoch_acc += acc.item()\n","        \n","    return epoch_loss / len(iter), epoch_acc / len(iter)"],"execution_count":30,"outputs":[]},{"cell_type":"code","metadata":{"id":"mYPICvIJwVV0","executionInfo":{"status":"ok","timestamp":1638689923169,"user_tz":-420,"elapsed":296,"user":{"displayName":"colab google","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15243667049266710387"}}},"source":["def epoch_time(start_time, end_time):\n","    elapsed_time = end_time - start_time\n","    elapsed_mins = int(elapsed_time / 60)\n","    elapsed_secs = int(elapsed_time - elapsed_mins * 60)\n","    return elapsed_mins, elapsed_secs"],"execution_count":32,"outputs":[]},{"cell_type":"code","metadata":{"id":"jds3I3w07D0t","executionInfo":{"status":"ok","timestamp":1638689928853,"user_tz":-420,"elapsed":266,"user":{"displayName":"colab google","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15243667049266710387"}}},"source":["EPOCH = 30\n","PATH = '/content/drive/MyDrive/ner/bilstm_cnn.pt'\n","best_valid_loss = float('inf')"],"execution_count":33,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XaqWUV0kwkDz","executionInfo":{"status":"ok","timestamp":1638637374086,"user_tz":-420,"elapsed":878403,"user":{"displayName":"colab google","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15243667049266710387"}},"outputId":"d0332397-5525-4d36-9e90-29d37615d172"},"source":["for epoch in range(EPOCH):\n","    start = time.time()\n","    train_loss, train_acc = train(model, train_iter, optimizer, criterion, LABEL.vocab.stoi['<pad>'])\n","    valid_loss, valid_acc = evaluate(model, valid_iter, criterion, LABEL.vocab.stoi['<pad>'])\n","    end = time.time()\n","    epoch_mins, epoch_secs = epoch_time(start, end)\n","    if valid_loss < best_valid_loss:\n","        best_valid_loss = valid_loss\n","        torch.save({\n","            'epoch' : epoch,\n","            'model_state_dict' : model.state_dict(),\n","            'optimizer_state_dict' : optimizer.state_dict(),\n","            'loss' : best_valid_loss\n","        }, PATH)\n","\n","    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n","    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n","    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch: 01 | Epoch Time: 0m 29s\n","\tTrain Loss: 0.420 | Train Acc: 87.36%\n","\t Val. Loss: 0.196 |  Val. Acc: 93.57%\n","Epoch: 02 | Epoch Time: 0m 29s\n","\tTrain Loss: 0.174 | Train Acc: 94.34%\n","\t Val. Loss: 0.119 |  Val. Acc: 96.36%\n","Epoch: 03 | Epoch Time: 0m 29s\n","\tTrain Loss: 0.124 | Train Acc: 96.09%\n","\t Val. Loss: 0.095 |  Val. Acc: 97.10%\n","Epoch: 04 | Epoch Time: 0m 28s\n","\tTrain Loss: 0.095 | Train Acc: 96.98%\n","\t Val. Loss: 0.089 |  Val. Acc: 97.22%\n","Epoch: 05 | Epoch Time: 0m 29s\n","\tTrain Loss: 0.077 | Train Acc: 97.58%\n","\t Val. Loss: 0.087 |  Val. Acc: 97.37%\n","Epoch: 06 | Epoch Time: 0m 29s\n","\tTrain Loss: 0.068 | Train Acc: 97.86%\n","\t Val. Loss: 0.091 |  Val. Acc: 97.48%\n","Epoch: 07 | Epoch Time: 0m 29s\n","\tTrain Loss: 0.059 | Train Acc: 98.17%\n","\t Val. Loss: 0.084 |  Val. Acc: 97.75%\n","Epoch: 08 | Epoch Time: 0m 29s\n","\tTrain Loss: 0.053 | Train Acc: 98.38%\n","\t Val. Loss: 0.084 |  Val. Acc: 97.71%\n","Epoch: 09 | Epoch Time: 0m 29s\n","\tTrain Loss: 0.048 | Train Acc: 98.49%\n","\t Val. Loss: 0.083 |  Val. Acc: 97.79%\n","Epoch: 10 | Epoch Time: 0m 29s\n","\tTrain Loss: 0.045 | Train Acc: 98.64%\n","\t Val. Loss: 0.087 |  Val. Acc: 97.64%\n","Epoch: 11 | Epoch Time: 0m 29s\n","\tTrain Loss: 0.040 | Train Acc: 98.76%\n","\t Val. Loss: 0.086 |  Val. Acc: 97.70%\n","Epoch: 12 | Epoch Time: 0m 29s\n","\tTrain Loss: 0.039 | Train Acc: 98.78%\n","\t Val. Loss: 0.084 |  Val. Acc: 97.86%\n","Epoch: 13 | Epoch Time: 0m 28s\n","\tTrain Loss: 0.039 | Train Acc: 98.82%\n","\t Val. Loss: 0.080 |  Val. Acc: 97.87%\n","Epoch: 14 | Epoch Time: 0m 28s\n","\tTrain Loss: 0.037 | Train Acc: 98.86%\n","\t Val. Loss: 0.081 |  Val. Acc: 97.95%\n","Epoch: 15 | Epoch Time: 0m 29s\n","\tTrain Loss: 0.035 | Train Acc: 98.91%\n","\t Val. Loss: 0.083 |  Val. Acc: 97.98%\n","Epoch: 16 | Epoch Time: 0m 29s\n","\tTrain Loss: 0.035 | Train Acc: 98.90%\n","\t Val. Loss: 0.092 |  Val. Acc: 97.89%\n","Epoch: 17 | Epoch Time: 0m 29s\n","\tTrain Loss: 0.033 | Train Acc: 98.98%\n","\t Val. Loss: 0.087 |  Val. Acc: 97.89%\n","Epoch: 18 | Epoch Time: 0m 29s\n","\tTrain Loss: 0.033 | Train Acc: 98.99%\n","\t Val. Loss: 0.090 |  Val. Acc: 97.83%\n","Epoch: 19 | Epoch Time: 0m 29s\n","\tTrain Loss: 0.032 | Train Acc: 99.00%\n","\t Val. Loss: 0.094 |  Val. Acc: 97.81%\n","Epoch: 20 | Epoch Time: 0m 29s\n","\tTrain Loss: 0.032 | Train Acc: 99.01%\n","\t Val. Loss: 0.085 |  Val. Acc: 97.89%\n","Epoch: 21 | Epoch Time: 0m 29s\n","\tTrain Loss: 0.032 | Train Acc: 99.01%\n","\t Val. Loss: 0.094 |  Val. Acc: 97.81%\n","Epoch: 22 | Epoch Time: 0m 29s\n","\tTrain Loss: 0.030 | Train Acc: 99.06%\n","\t Val. Loss: 0.093 |  Val. Acc: 97.75%\n","Epoch: 23 | Epoch Time: 0m 29s\n","\tTrain Loss: 0.031 | Train Acc: 99.06%\n","\t Val. Loss: 0.096 |  Val. Acc: 97.72%\n","Epoch: 24 | Epoch Time: 0m 29s\n","\tTrain Loss: 0.031 | Train Acc: 99.04%\n","\t Val. Loss: 0.095 |  Val. Acc: 97.88%\n","Epoch: 25 | Epoch Time: 0m 29s\n","\tTrain Loss: 0.032 | Train Acc: 99.01%\n","\t Val. Loss: 0.092 |  Val. Acc: 97.96%\n","Epoch: 26 | Epoch Time: 0m 29s\n","\tTrain Loss: 0.030 | Train Acc: 99.07%\n","\t Val. Loss: 0.096 |  Val. Acc: 97.86%\n","Epoch: 27 | Epoch Time: 0m 29s\n","\tTrain Loss: 0.030 | Train Acc: 99.06%\n","\t Val. Loss: 0.095 |  Val. Acc: 97.94%\n","Epoch: 28 | Epoch Time: 0m 29s\n","\tTrain Loss: 0.031 | Train Acc: 99.05%\n","\t Val. Loss: 0.088 |  Val. Acc: 97.93%\n","Epoch: 29 | Epoch Time: 0m 29s\n","\tTrain Loss: 0.031 | Train Acc: 99.03%\n","\t Val. Loss: 0.098 |  Val. Acc: 97.83%\n","Epoch: 30 | Epoch Time: 0m 29s\n","\tTrain Loss: 0.034 | Train Acc: 98.96%\n","\t Val. Loss: 0.097 |  Val. Acc: 97.73%\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DVqGYapNzXHm","executionInfo":{"status":"ok","timestamp":1638689961255,"user_tz":-420,"elapsed":3588,"user":{"displayName":"colab google","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15243667049266710387"}},"outputId":"c2a281b4-b2e3-4118-b5a3-a1960c94c996"},"source":["checkpoint = torch.load(PATH)\n","model.load_state_dict(checkpoint['model_state_dict'])\n","test_loss, test_acc = evaluate(model, test_iter, criterion, LABEL.vocab.stoi['<pad>'])\n","print(f'loss {test_loss:.3f} | acc {test_acc*100:.2f}%')"],"execution_count":35,"outputs":[{"output_type":"stream","name":"stdout","text":["loss 0.154 | acc 96.32%\n"]}]},{"cell_type":"code","metadata":{"id":"HVYMgK_zFDf3","executionInfo":{"status":"ok","timestamp":1638689994325,"user_tz":-420,"elapsed":2990,"user":{"displayName":"colab google","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15243667049266710387"}}},"source":["model.eval()\n","preds = []\n","labels = []\n","with torch.no_grad():\n","    for batch in test_iter:\n","        #pred = [sent, batch size, output_dim]\n","        pred = torch.argmax(model(batch.text, batch.char), dim = 2)  #pred = [sent, batch size]\n","        pred = pred.view(-1).tolist()  #pred = [sent * batch size]\n","        label = batch.label.view(-1).tolist()  #label = [sent * batch size]\n","        for idx in range(len(label)):\n","           if label[idx] < 2 or pred[idx] < 2: continue\n","           preds.append(LABEL.vocab.itos[pred[idx]])\n","           labels.append(LABEL.vocab.itos[label[idx]])"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W5zZtXN2IQcY","executionInfo":{"status":"ok","timestamp":1638690002407,"user_tz":-420,"elapsed":706,"user":{"displayName":"colab google","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15243667049266710387"}},"outputId":"79971752-b79f-4042-dd36-1d8f025757ab"},"source":["from sklearn.metrics import classification_report\n","print(classification_report(preds, labels, digits = 4))"],"execution_count":37,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","       B-LOC     0.8933    0.9169    0.9049      1588\n","      B-MISC     0.8328    0.8051    0.8187       662\n","       B-ORG     0.8924    0.8207    0.8551      1707\n","       B-PER     0.8503    0.9513    0.8979      1355\n","       I-LOC     0.8279    0.7891    0.8080       256\n","      I-MISC     0.8011    0.7062    0.7506       211\n","       I-ORG     0.8983    0.8337    0.8648       848\n","       I-PER     0.9229    0.9688    0.9453      1088\n","\n","    accuracy                         0.8802      7715\n","   macro avg     0.8649    0.8490    0.8557      7715\n","weighted avg     0.8804    0.8802    0.8791      7715\n","\n"]}]},{"cell_type":"code","metadata":{"id":"JW7eIeEvdUsd","executionInfo":{"status":"ok","timestamp":1638694565081,"user_tz":-420,"elapsed":248,"user":{"displayName":"colab google","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15243667049266710387"}}},"source":["def pred_sent(sent):\n","    model.eval()\n","    nlp = spacy.load('en_core_web_sm')\n","    tokens = [token.text for token in nlp(sent)]\n","    chars = []\n","    max_word_len = -1\n","    for token in tokens:\n","        if max_word_len < len(token): max_word_len = len(token)\n","        chars.append([char for char in token])\n","\n","    for char_list in chars:\n","        for _ in range(max_word_len - len(char_list)):\n","            char_list.append('<pad>')\n","\n","    token_idx = [TEXT.vocab.stoi[token] for token in tokens]\n","    \n","    for x in range(len(chars)):\n","        for y in range(max_word_len):\n","            chars[x][y] = CHAR.vocab.stoi[chars[x][y]]\n","    \n","    token_tensor = torch.LongTensor(token_idx).unsqueeze(-1).to(device)\n","    char_tensor = torch.LongTensor(chars).unsqueeze(0).to(device)\n","    pred = model(token_tensor, char_tensor).argmax(-1).squeeze()\n","    predicted_tags = [LABEL.vocab.itos[x] for x in pred]\n","\n","    return tokens, predicted_tags"],"execution_count":80,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":645},"id":"bY5TA_N1sA6I","executionInfo":{"status":"ok","timestamp":1638696665060,"user_tz":-420,"elapsed":1001,"user":{"displayName":"colab google","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"15243667049266710387"}},"outputId":"6acfea4e-a7df-425b-9173-97786494abc5"},"source":["sentence = 'John lives in New York. He just graduted from Harvard University. He is working for Google now'\n","tokens, predicted_tags = pred_sent(sentence)\n","\n","test_df = pd.DataFrame({'token' : tokens,\n","                        'predicted_tag': predicted_tags})\n","test_df"],"execution_count":113,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>token</th>\n","      <th>predicted_tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>John</td>\n","      <td>B-PER</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>lives</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>in</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>New</td>\n","      <td>B-LOC</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>York</td>\n","      <td>I-LOC</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>.</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>He</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>just</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>graduted</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>from</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>Harvard</td>\n","      <td>B-ORG</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>University</td>\n","      <td>I-ORG</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>.</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>He</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>is</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>working</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>for</td>\n","      <td>O</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>Google</td>\n","      <td>B-MISC</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>now</td>\n","      <td>O</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["         token predicted_tag\n","0         John         B-PER\n","1        lives             O\n","2           in             O\n","3          New         B-LOC\n","4         York         I-LOC\n","5            .             O\n","6           He             O\n","7         just             O\n","8     graduted             O\n","9         from             O\n","10     Harvard         B-ORG\n","11  University         I-ORG\n","12           .             O\n","13          He             O\n","14          is             O\n","15     working             O\n","16         for             O\n","17      Google        B-MISC\n","18         now             O"]},"metadata":{},"execution_count":113}]}]}